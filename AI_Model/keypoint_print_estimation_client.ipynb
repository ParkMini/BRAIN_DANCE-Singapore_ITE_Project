{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Live Human Pose Estimation with OpenVINO™\n",
    "\n",
    "# This notebook demonstrates live pose estimation with OpenVINO, using the OpenPose human-pose-estimation-0001 model from Open Model Zoo.\n",
    "\n",
    "# Imports\n",
    "%pip install -q \"openvino>=2023.1.0\" opencv-python websockets\n",
    "\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import openvino as ov\n",
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "\n",
    "from decoder import OpenPoseDecoder\n",
    "\n",
    "# Download utility script\n",
    "urllib.request.urlretrieve(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py\",\n",
    "    filename=\"notebook_utils.py\",\n",
    ")\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils\n",
    "\n",
    "# Download the model\n",
    "base_model_dir = Path(\"model\")\n",
    "model_name = \"human-pose-estimation-0001\"\n",
    "precision = \"FP16-INT8\"\n",
    "model_path = base_model_dir / \"intel\" / model_name / precision / f\"{model_name}.xml\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    model_url_dir = f\"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/3/{model_name}/{precision}/\"\n",
    "    utils.download_file(model_url_dir + model_name + '.xml', model_path.name, model_path.parent)\n",
    "    utils.download_file(model_url_dir + model_name + '.bin', model_path.with_suffix('.bin').name, model_path.parent)\n",
    "\n",
    "# Initialize OpenVINO Runtime\n",
    "core = ov.Core()\n",
    "model = core.read_model(model_path)\n",
    "compiled_model = core.compile_model(model=model, device_name=\"AUTO\", config={\"PERFORMANCE_HINT\": \"LATENCY\"})\n",
    "\n",
    "# Get the input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = compiled_model.outputs\n",
    "height, width = list(input_layer.shape)[2:]\n",
    "\n",
    "# Initialize decoder\n",
    "decoder = OpenPoseDecoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D pooling in numpy\n",
    "def pool2d(A, kernel_size, stride, padding, pool_mode=\"max\"):\n",
    "    A = np.pad(A, padding, mode=\"constant\")\n",
    "    output_shape = (\n",
    "        (A.shape[0] - kernel_size) // stride + 1,\n",
    "        (A.shape[1] - kernel_size) // stride + 1,\n",
    "    )\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(\n",
    "        A,\n",
    "        shape=output_shape + kernel_size,\n",
    "        strides=(stride * A.strides[0], stride * A.strides[1]) + A.strides\n",
    "    )\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "    if pool_mode == \"max\":\n",
    "        return A_w.max(axis=(1, 2)).reshape(output_shape)\n",
    "    elif pool_mode == \"avg\":\n",
    "        return A_w.mean(axis=(1, 2)).reshape(output_shape)\n",
    "\n",
    "# Non maximum suppression\n",
    "def heatmap_nms(heatmaps, pooled_heatmaps):\n",
    "    return heatmaps * (heatmaps == pooled_heatmaps)\n",
    "\n",
    "# Get poses from results\n",
    "def process_results(img, pafs, heatmaps):\n",
    "    pooled_heatmaps = np.array(\n",
    "        [[pool2d(h, kernel_size=3, stride=1, padding=1, pool_mode=\"max\") for h in heatmaps[0]]]\n",
    "    )\n",
    "    nms_heatmaps = heatmap_nms(heatmaps, pooled_heatmaps)\n",
    "    poses, scores = decoder(heatmaps, nms_heatmaps, pafs)\n",
    "    output_shape = list(compiled_model.output(index=0).partial_shape)\n",
    "    output_scale = img.shape[1] / output_shape[3].get_length(), img.shape[0] / output_shape[2].get_length()\n",
    "    poses[:, :, :2] *= output_scale\n",
    "    return poses, scores\n",
    "\n",
    "# Draw pose overlays on the image\n",
    "colors = ((255, 0, 0), (255, 0, 255), (170, 0, 255), (255, 0, 85), (255, 0, 170), (85, 255, 0),\n",
    "          (255, 170, 0), (0, 255, 0), (255, 255, 0), (0, 255, 85), (170, 255, 0), (0, 85, 255),\n",
    "          (0, 255, 170), (0, 0, 255), (0, 255, 255), (85, 0, 255), (0, 170, 255))\n",
    "\n",
    "default_skeleton = ((15, 13), (13, 11), (16, 14), (14, 12), (11, 12), (5, 11), (6, 12), (5, 6), (5, 7),\n",
    "                    (6, 8), (7, 9), (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6))\n",
    "\n",
    "keypoint_names = [\n",
    "    \"코\", \"왼쪽 눈\", \"오른쪽 눈\", \"왼쪽 귀\", \"오른쪽 귀\",\n",
    "    \"왼쪽 어깨\", \"오른쪽 어깨\", \"왼쪽 팔꿈치\", \"오른쪽 팔꿈치\",\n",
    "    \"왼쪽 손목\", \"오른쪽 손목\", \"왼쪽 엉덩이\", \"오른쪽 엉덩이\",\n",
    "    \"왼쪽 무릎\", \"오른쪽 무릎\", \"왼쪽 발목\", \"오른쪽 발목\"\n",
    "]\n",
    "\n",
    "def draw_poses(img, poses, point_score_threshold, skeleton=default_skeleton):\n",
    "    if poses.size == 0:\n",
    "        return img\n",
    "    img_limbs = np.copy(img)\n",
    "    for pose in poses:\n",
    "        points = pose[:, :2].astype(np.int32)\n",
    "        points_scores = pose[:, 2]\n",
    "        for i, (p, v) in enumerate(zip(points, points_scores)):\n",
    "            if v > point_score_threshold:\n",
    "                cv2.circle(img, tuple(p), 1, colors[i], 2)\n",
    "        for i, j in skeleton:\n",
    "            if points_scores[i] > point_score_threshold and points_scores[j] > point_score_threshold:\n",
    "                cv2.line(img_limbs, tuple(points[i]), tuple(points[j]), color=colors[j], thickness=4)\n",
    "    cv2.addWeighted(img, 0.4, img_limbs, 0.6, 0, dst=img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import websockets\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "async def send_keypoints(uri, keypoints_data):\n",
    "    while True:\n",
    "        try:\n",
    "            async with websockets.connect(uri) as websocket:\n",
    "                await websocket.send(json.dumps(keypoints_data))\n",
    "                break\n",
    "        except (websockets.ConnectionClosedError, ConnectionRefusedError):\n",
    "            print(\"Connection failed, retrying in 1 second...\")\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "def run_pose_estimation(source=0, flip=False, use_popup=False, skip_first_frames=0, show_keypoint_names=True, websocket_uri=\"ws://10.10.10.1:12345\"):\n",
    "    pafs_output_key = compiled_model.output(\"Mconv7_stage2_L1\")\n",
    "    heatmaps_output_key = compiled_model.output(\"Mconv7_stage2_L2\")\n",
    "    player = None\n",
    "    try:\n",
    "        player = utils.VideoPlayer(source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        last_print_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "\n",
    "            black_background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            input_img = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "            input_img = input_img.transpose((2, 0, 1))[np.newaxis, ...]\n",
    "\n",
    "            start_time = time.time()\n",
    "            results = compiled_model([input_img])\n",
    "            stop_time = time.time()\n",
    "\n",
    "            pafs = results[pafs_output_key]\n",
    "            heatmaps = results[heatmaps_output_key]\n",
    "            poses, scores = process_results(frame, pafs, heatmaps)\n",
    "\n",
    "            black_background = draw_poses(black_background, poses, 0.1)\n",
    "            \n",
    "            processing_times.append(stop_time - start_time)\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            cv2.putText(black_background, f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if current_time - last_print_time >= 1:\n",
    "                keypoints_data = []\n",
    "                if poses.size > 0:\n",
    "                    for pose in poses:\n",
    "                        keypoints = pose[:, :2].astype(int)\n",
    "                        center_x, center_y = keypoints[11]  # assuming 11 is the hip keypoint\n",
    "                        keypoints_dict = {}\n",
    "                        if show_keypoint_names:\n",
    "                            print(f\"중심점 (엉덩이) 가정 위치: ({center_x}, {center_y})\")\n",
    "                            print(\"상대 키포인트 (이름, x, y):\")\n",
    "                        for idx, keypoint in enumerate(keypoints):\n",
    "                            relative_x = keypoint[0] - center_x\n",
    "                            relative_y = keypoint[1] - center_y\n",
    "                            keypoints_dict[keypoint_names[idx]] = (relative_x, relative_y)\n",
    "                            if show_keypoint_names:\n",
    "                                print(f\"{keypoint_names[idx]}: ({relative_x}, {relative_y})\")\n",
    "                            else:\n",
    "                                print(f\"({relative_x}, {relative_y})\")\n",
    "                        keypoints_data.append(keypoints_dict)\n",
    "                else:\n",
    "                    print(\"No poses detected.\")\n",
    "                \n",
    "                asyncio.run(send_keypoints(websocket_uri, keypoints_data))\n",
    "                last_print_time = current_time\n",
    "\n",
    "            if use_popup:\n",
    "                cv2.imshow(title, black_background)\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                _, encoded_img = cv2.imencode(\".jpg\", black_background, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "                img_display = Image(data=encoded_img)\n",
    "                clear_output(wait=True)\n",
    "                display(img_display)\n",
    "            \n",
    "                cv2.imwrite(\"../static/ai.png\", black_background)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run Live Pose Estimation\n",
    "USE_WEBCAM = False\n",
    "cam_id = 0\n",
    "video_file = \"./y2mate.com - Just Dance 2017 PC Unlimited Rasputin 4K_480p.mp4\"\n",
    "source = cam_id if USE_WEBCAM else video_file\n",
    "\n",
    "additional_options = {\"skip_first_frames\": 500} if not USE_WEBCAM else {}\n",
    "run_pose_estimation(source=source, flip=isinstance(source, int), use_popup=False, **additional_options, show_keypoint_names=True, websocket_uri=\"ws://10.10.10.1:12345\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
