{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Live Human Pose Estimation with OpenVINO™\n",
    "\n",
    "# This notebook demonstrates live pose estimation with OpenVINO, using the OpenPose human-pose-estimation-0001 model from Open Model Zoo.\n",
    "\n",
    "# Imports\n",
    "%pip install -q \"openvino>=2023.1.0\" opencv-python\n",
    "\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import openvino as ov\n",
    "\n",
    "from decoder import OpenPoseDecoder\n",
    "\n",
    "# Download utility script\n",
    "urllib.request.urlretrieve(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py\",\n",
    "    filename=\"notebook_utils.py\",\n",
    ")\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils\n",
    "\n",
    "# Download the model\n",
    "base_model_dir = Path(\"model\")\n",
    "model_name = \"human-pose-estimation-0001\"\n",
    "precision = \"FP16-INT8\"\n",
    "model_path = base_model_dir / \"intel\" / model_name / precision / f\"{model_name}.xml\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    model_url_dir = f\"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/3/{model_name}/{precision}/\"\n",
    "    utils.download_file(model_url_dir + model_name + '.xml', model_path.name, model_path.parent)\n",
    "    utils.download_file(model_url_dir + model_name + '.bin', model_path.with_suffix('.bin').name, model_path.parent)\n",
    "\n",
    "# Initialize OpenVINO Runtime\n",
    "core = ov.Core()\n",
    "model = core.read_model(model_path)\n",
    "compiled_model = core.compile_model(model=model, device_name=\"AUTO\", config={\"PERFORMANCE_HINT\": \"LATENCY\"})\n",
    "\n",
    "# Get the input and output names of nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layers = compiled_model.outputs\n",
    "height, width = list(input_layer.shape)[2:]\n",
    "\n",
    "# Initialize decoder\n",
    "decoder = OpenPoseDecoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D pooling in numpy\n",
    "def pool2d(A, kernel_size, stride, padding, pool_mode=\"max\"):\n",
    "    A = np.pad(A, padding, mode=\"constant\")\n",
    "    output_shape = (\n",
    "        (A.shape[0] - kernel_size) // stride + 1,\n",
    "        (A.shape[1] - kernel_size) // stride + 1,\n",
    "    )\n",
    "    kernel_size = (kernel_size, kernel_size)\n",
    "    A_w = as_strided(\n",
    "        A,\n",
    "        shape=output_shape + kernel_size,\n",
    "        strides=(stride * A.strides[0], stride * A.strides[1]) + A.strides\n",
    "    )\n",
    "    A_w = A_w.reshape(-1, *kernel_size)\n",
    "    if pool_mode == \"max\":\n",
    "        return A_w.max(axis=(1, 2)).reshape(output_shape)\n",
    "    elif pool_mode == \"avg\":\n",
    "        return A_w.mean(axis=(1, 2)).reshape(output_shape)\n",
    "\n",
    "# Non maximum suppression\n",
    "def heatmap_nms(heatmaps, pooled_heatmaps):\n",
    "    return heatmaps * (heatmaps == pooled_heatmaps)\n",
    "\n",
    "# Get poses from results\n",
    "def process_results(img, pafs, heatmaps):\n",
    "    pooled_heatmaps = np.array(\n",
    "        [[pool2d(h, kernel_size=3, stride=1, padding=1, pool_mode=\"max\") for h in heatmaps[0]]]\n",
    "    )\n",
    "    nms_heatmaps = heatmap_nms(heatmaps, pooled_heatmaps)\n",
    "    poses, scores = decoder(heatmaps, nms_heatmaps, pafs)\n",
    "    output_shape = list(compiled_model.output(index=0).partial_shape)\n",
    "    output_scale = img.shape[1] / output_shape[3].get_length(), img.shape[0] / output_shape[2].get_length()\n",
    "    poses[:, :, :2] *= output_scale\n",
    "    return poses, scores\n",
    "\n",
    "# Draw pose overlays on the image\n",
    "colors = ((255, 0, 0), (255, 0, 255), (170, 0, 255), (255, 0, 85), (255, 0, 170), (85, 255, 0),\n",
    "          (255, 170, 0), (0, 255, 0), (255, 255, 0), (0, 255, 85), (170, 255, 0), (0, 85, 255),\n",
    "          (0, 255, 170), (0, 0, 255), (0, 255, 255), (85, 0, 255), (0, 170, 255))\n",
    "\n",
    "default_skeleton = ((15, 13), (13, 11), (16, 14), (14, 12), (11, 12), (5, 11), (6, 12), (5, 6), (5, 7),\n",
    "                    (6, 8), (7, 9), (8, 10), (1, 2), (0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6))\n",
    "\n",
    "def draw_poses(img, poses, point_score_threshold, skeleton=default_skeleton):\n",
    "    if poses.size == 0:\n",
    "        return img\n",
    "    img_limbs = np.copy(img)\n",
    "    for pose in poses:\n",
    "        points = pose[:, :2].astype(np.int32)\n",
    "        points_scores = pose[:, 2]\n",
    "        for i, (p, v) in enumerate(zip(points, points_scores)):\n",
    "            if v > point_score_threshold:\n",
    "                cv2.circle(img, tuple(p), 1, colors[i], 2)\n",
    "        for i, j in skeleton:\n",
    "            if points_scores[i] > point_score_threshold and points_scores[j] > point_score_threshold:\n",
    "                cv2.line(img_limbs, tuple(points[i]), tuple(points[j]), color=colors[j], thickness=4)\n",
    "    cv2.addWeighted(img, 0.4, img_limbs, 0.6, 0, dst=img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No poses detected.\n",
      "Center point (hip) assumed at: (385, 243)\n",
      "Relative keypoints (x, y):\n",
      "(38, -82)\n",
      "(45, -90)\n",
      "(30, -90)\n",
      "(53, -90)\n",
      "(23, -82)\n",
      "(60, -45)\n",
      "(15, -45)\n",
      "(68, 0)\n",
      "(0, 0)\n",
      "(68, 30)\n",
      "(-7, 38)\n",
      "(60, 38)\n",
      "(23, 45)\n",
      "(68, 98)\n",
      "(23, 113)\n",
      "(68, 158)\n",
      "(30, 165)\n",
      "Center point (hip) assumed at: (415, 168)\n",
      "Relative keypoints (x, y):\n",
      "(53, 45)\n",
      "(60, 38)\n",
      "(45, 38)\n",
      "(-415, -168)\n",
      "(45, 30)\n",
      "(60, 68)\n",
      "(23, 38)\n",
      "(75, 113)\n",
      "(0, 0)\n",
      "(90, 143)\n",
      "(-22, -30)\n",
      "(45, 143)\n",
      "(15, 135)\n",
      "(53, 210)\n",
      "(-7, 158)\n",
      "(53, 263)\n",
      "(-415, -168)\n",
      "Center point (hip) assumed at: (393, 251)\n",
      "Relative keypoints (x, y):\n",
      "(37, -83)\n",
      "(45, -90)\n",
      "(30, -90)\n",
      "(52, -90)\n",
      "(15, -83)\n",
      "(67, -60)\n",
      "(15, -45)\n",
      "(82, -83)\n",
      "(0, 0)\n",
      "(105, -113)\n",
      "(-15, 45)\n",
      "(60, 37)\n",
      "(22, 37)\n",
      "(60, 90)\n",
      "(22, 105)\n",
      "(52, 142)\n",
      "(30, 157)\n",
      "Center point (hip) assumed at: (400, 176)\n",
      "Relative keypoints (x, y):\n",
      "(53, 22)\n",
      "(60, 15)\n",
      "(53, 15)\n",
      "(75, 22)\n",
      "(45, 7)\n",
      "(83, 52)\n",
      "(30, 22)\n",
      "(98, 97)\n",
      "(0, 0)\n",
      "(113, 127)\n",
      "(-22, -30)\n",
      "(68, 142)\n",
      "(23, 135)\n",
      "(68, 202)\n",
      "(23, 187)\n",
      "(68, 247)\n",
      "(8, 247)\n",
      "Center point (hip) assumed at: (385, 251)\n",
      "Relative keypoints (x, y):\n",
      "(38, -75)\n",
      "(45, -83)\n",
      "(30, -83)\n",
      "(53, -83)\n",
      "(23, -83)\n",
      "(68, -60)\n",
      "(15, -38)\n",
      "(98, -83)\n",
      "(0, 0)\n",
      "(113, -98)\n",
      "(-22, 37)\n",
      "(60, 37)\n",
      "(23, 37)\n",
      "(68, 90)\n",
      "(23, 105)\n",
      "(68, 142)\n",
      "(30, 157)\n",
      "Center point (hip) assumed at: (370, 161)\n",
      "Relative keypoints (x, y):\n",
      "(68, 37)\n",
      "(83, 30)\n",
      "(60, 30)\n",
      "(90, 37)\n",
      "(60, 22)\n",
      "(90, 75)\n",
      "(38, 45)\n",
      "(113, 105)\n",
      "(0, 0)\n",
      "(135, 142)\n",
      "(-7, 0)\n",
      "(75, 157)\n",
      "(38, 142)\n",
      "(68, 217)\n",
      "(23, 180)\n",
      "(60, 270)\n",
      "(60, 285)\n",
      "Center point (hip) assumed at: (393, 251)\n",
      "Relative keypoints (x, y):\n",
      "(30, -75)\n",
      "(37, -83)\n",
      "(22, -83)\n",
      "(52, -83)\n",
      "(15, -83)\n",
      "(67, -60)\n",
      "(15, -38)\n",
      "(90, -83)\n",
      "(0, 0)\n",
      "(105, -105)\n",
      "(-15, 30)\n",
      "(60, 30)\n",
      "(22, 37)\n",
      "(60, 90)\n",
      "(22, 105)\n",
      "(60, 150)\n",
      "(37, 150)\n",
      "Center point (hip) assumed at: (393, 161)\n",
      "Relative keypoints (x, y):\n",
      "(52, 30)\n",
      "(60, 22)\n",
      "(-393, -161)\n",
      "(75, 30)\n",
      "(-393, -161)\n",
      "(82, 60)\n",
      "(37, 37)\n",
      "(120, 120)\n",
      "(0, 0)\n",
      "(142, 135)\n",
      "(-15, 0)\n",
      "(37, 135)\n",
      "(37, 135)\n",
      "(7, 172)\n",
      "(0, 165)\n",
      "(30, 210)\n",
      "(37, 210)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(468, 303)\n",
      "(0, 0)\n",
      "(460, 363)\n",
      "(0, 0)\n",
      "(453, 401)\n",
      "Center point (hip) assumed at: (393, 251)\n",
      "Relative keypoints (x, y):\n",
      "(45, -75)\n",
      "(52, -83)\n",
      "(37, -83)\n",
      "(67, -83)\n",
      "(30, -90)\n",
      "(75, -60)\n",
      "(22, -45)\n",
      "(112, -75)\n",
      "(0, 0)\n",
      "(127, -90)\n",
      "(-15, 22)\n",
      "(60, 45)\n",
      "(30, 45)\n",
      "(60, 105)\n",
      "(30, 105)\n",
      "(60, 150)\n",
      "(37, 150)\n",
      "Center point (hip) assumed at: (378, 176)\n",
      "Relative keypoints (x, y):\n",
      "(75, 0)\n",
      "(82, -8)\n",
      "(75, -8)\n",
      "(90, 0)\n",
      "(60, -15)\n",
      "(97, 30)\n",
      "(45, 15)\n",
      "(120, 60)\n",
      "(0, 0)\n",
      "(150, 90)\n",
      "(-15, 0)\n",
      "(90, 112)\n",
      "(52, 105)\n",
      "(90, 172)\n",
      "(30, 157)\n",
      "(90, 240)\n",
      "(52, 210)\n",
      "Center point (hip) assumed at: (393, 251)\n",
      "Relative keypoints (x, y):\n",
      "(52, -90)\n",
      "(60, -98)\n",
      "(45, -98)\n",
      "(67, -98)\n",
      "(45, -98)\n",
      "(82, -68)\n",
      "(30, -53)\n",
      "(135, -83)\n",
      "(0, 0)\n",
      "(142, -90)\n",
      "(-23, 15)\n",
      "(75, 37)\n",
      "(37, 45)\n",
      "(75, 112)\n",
      "(45, 112)\n",
      "(75, 172)\n",
      "(52, 172)\n",
      "Center point (hip) assumed at: (363, 198)\n",
      "Relative keypoints (x, y):\n",
      "(75, -37)\n",
      "(82, -45)\n",
      "(75, -45)\n",
      "(97, -45)\n",
      "(67, -52)\n",
      "(112, -7)\n",
      "(52, -15)\n",
      "(165, 0)\n",
      "(0, 0)\n",
      "(180, 8)\n",
      "(-15, 8)\n",
      "(97, 83)\n",
      "(60, 83)\n",
      "(97, 158)\n",
      "(45, 143)\n",
      "(97, 203)\n",
      "(60, 195)\n",
      "Center point (hip) assumed at: (370, 228)\n",
      "Relative keypoints (x, y):\n",
      "(68, -52)\n",
      "(68, -52)\n",
      "(60, -52)\n",
      "(83, -52)\n",
      "(53, -60)\n",
      "(90, -22)\n",
      "(38, -22)\n",
      "(120, -22)\n",
      "(0, 0)\n",
      "(90, -45)\n",
      "(15, 0)\n",
      "(75, 60)\n",
      "(38, 60)\n",
      "(83, 120)\n",
      "(0, 120)\n",
      "(83, 173)\n",
      "(23, 165)\n",
      "Center point (hip) assumed at: (460, 191)\n",
      "Relative keypoints (x, y):\n",
      "(-22, -23)\n",
      "(-15, -30)\n",
      "(-22, -30)\n",
      "(-460, -191)\n",
      "(-30, -30)\n",
      "(-60, 0)\n",
      "(-52, 0)\n",
      "(0, 7)\n",
      "(0, 0)\n",
      "(0, -30)\n",
      "(8, -38)\n",
      "(-52, 90)\n",
      "(-15, 97)\n",
      "(-97, 150)\n",
      "(0, 157)\n",
      "(-112, 195)\n",
      "(-7, 217)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(400, 191)\n",
      "(0, 0)\n",
      "(468, 198)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(408, 281)\n",
      "(438, 281)\n",
      "(355, 326)\n",
      "(460, 356)\n",
      "(355, 378)\n",
      "(445, 408)\n",
      "Center point (hip) assumed at: (468, 198)\n",
      "Relative keypoints (x, y):\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-30, -30)\n",
      "(-468, -198)\n",
      "(-53, -7)\n",
      "(-468, -198)\n",
      "(0, 0)\n",
      "(-468, -198)\n",
      "(0, -45)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "(-468, -198)\n",
      "Center point (hip) assumed at: (445, 198)\n",
      "Relative keypoints (x, y):\n",
      "(-7, -37)\n",
      "(0, -37)\n",
      "(-15, -37)\n",
      "(8, -30)\n",
      "(-22, -37)\n",
      "(-7, 0)\n",
      "(-45, 0)\n",
      "(23, 15)\n",
      "(0, 0)\n",
      "(30, -30)\n",
      "(-445, -198)\n",
      "(-7, 83)\n",
      "(-37, 83)\n",
      "(23, 150)\n",
      "(-82, 135)\n",
      "(15, 210)\n",
      "(-67, 195)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(408, 191)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(415, 183)\n",
      "(0, 0)\n",
      "(438, 213)\n",
      "(400, 213)\n",
      "(445, 251)\n",
      "(0, 0)\n",
      "(453, 288)\n",
      "(0, 0)\n",
      "(438, 296)\n",
      "(400, 296)\n",
      "(453, 363)\n",
      "(348, 333)\n",
      "(0, 0)\n",
      "(340, 401)\n",
      "Center point (hip) assumed at: (408, 191)\n",
      "Relative keypoints (x, y):\n",
      "(15, -38)\n",
      "(22, -45)\n",
      "(15, -45)\n",
      "(30, -38)\n",
      "(0, -38)\n",
      "(30, 0)\n",
      "(-15, -8)\n",
      "(45, 0)\n",
      "(0, 0)\n",
      "(52, -38)\n",
      "(15, 0)\n",
      "(30, 90)\n",
      "(-8, 90)\n",
      "(37, 165)\n",
      "(-60, 142)\n",
      "(30, 225)\n",
      "(-60, 202)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(430, 191)\n",
      "(438, 176)\n",
      "(423, 176)\n",
      "(445, 176)\n",
      "(415, 176)\n",
      "(453, 206)\n",
      "(400, 198)\n",
      "(468, 206)\n",
      "(0, 0)\n",
      "(468, 191)\n",
      "(0, 0)\n",
      "(430, 288)\n",
      "(393, 288)\n",
      "(445, 356)\n",
      "(348, 326)\n",
      "(438, 408)\n",
      "(333, 386)\n",
      "Center point (hip) assumed at: (430, 206)\n",
      "Relative keypoints (x, y):\n",
      "(15, -38)\n",
      "(15, -45)\n",
      "(8, -45)\n",
      "(23, -38)\n",
      "(0, -45)\n",
      "(8, -8)\n",
      "(-22, -15)\n",
      "(45, 0)\n",
      "(0, 0)\n",
      "(53, -30)\n",
      "(23, 7)\n",
      "(8, 90)\n",
      "(-30, 82)\n",
      "(8, 157)\n",
      "(-75, 150)\n",
      "(0, 217)\n",
      "(-105, 187)\n",
      "Center point (hip) assumed at: (370, 348)\n",
      "Relative keypoints (x, y):\n",
      "(38, -52)\n",
      "(38, -60)\n",
      "(30, -60)\n",
      "(45, -60)\n",
      "(23, -60)\n",
      "(60, -37)\n",
      "(8, -37)\n",
      "(75, 0)\n",
      "(0, 0)\n",
      "(53, 8)\n",
      "(23, 15)\n",
      "(60, 38)\n",
      "(15, 30)\n",
      "(53, 60)\n",
      "(-15, 23)\n",
      "(-370, -348)\n",
      "(-370, -348)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(445, 288)\n",
      "(408, 288)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "No poses detected.\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(408, 258)\n",
      "(415, 251)\n",
      "(408, 251)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(430, 281)\n",
      "(0, 0)\n",
      "(475, 303)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "Center point (hip) assumed at: (370, 281)\n",
      "Relative keypoints (x, y):\n",
      "(68, -38)\n",
      "(75, -45)\n",
      "(68, -45)\n",
      "(90, -38)\n",
      "(60, -45)\n",
      "(98, -15)\n",
      "(38, -23)\n",
      "(128, 15)\n",
      "(0, 0)\n",
      "(98, 7)\n",
      "(38, -8)\n",
      "(75, 67)\n",
      "(38, 67)\n",
      "(98, 112)\n",
      "(8, 105)\n",
      "(86, 184)\n",
      "(30, 180)\n",
      "Center point (hip) assumed at: (0, 0)\n",
      "Relative keypoints (x, y):\n",
      "(415, 228)\n",
      "(415, 221)\n",
      "(408, 221)\n",
      "(0, 0)\n",
      "(400, 228)\n",
      "(430, 251)\n",
      "(385, 258)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "Center point (hip) assumed at: (370, 221)\n",
      "Relative keypoints (x, y):\n",
      "(83, -15)\n",
      "(90, -23)\n",
      "(75, -30)\n",
      "(98, -23)\n",
      "(68, -30)\n",
      "(113, 15)\n",
      "(45, 0)\n",
      "(173, 30)\n",
      "(0, 0)\n",
      "(218, 15)\n",
      "(-30, 0)\n",
      "(83, 97)\n",
      "(45, 97)\n",
      "(120, 142)\n",
      "(8, 142)\n",
      "(98, 172)\n",
      "(0, 195)\n",
      "Center point (hip) assumed at: (408, 251)\n",
      "Relative keypoints (x, y):\n",
      "(37, -68)\n",
      "(45, -75)\n",
      "(30, -75)\n",
      "(60, -75)\n",
      "(22, -75)\n",
      "(75, -38)\n",
      "(7, -38)\n",
      "(82, 7)\n",
      "(0, 0)\n",
      "(60, 15)\n",
      "(22, 15)\n",
      "(60, 45)\n",
      "(22, 45)\n",
      "(82, 97)\n",
      "(0, 90)\n",
      "(82, 157)\n",
      "(-8, 157)\n",
      "Center point (hip) assumed at: (408, 221)\n",
      "Relative keypoints (x, y):\n",
      "(75, -45)\n",
      "(82, -53)\n",
      "(75, -53)\n",
      "(90, -53)\n",
      "(60, -53)\n",
      "(97, -15)\n",
      "(37, -23)\n",
      "(97, 37)\n",
      "(0, 0)\n",
      "(-408, -221)\n",
      "(-30, 7)\n",
      "(82, 75)\n",
      "(45, 75)\n",
      "(90, 142)\n",
      "(7, 127)\n",
      "(90, 172)\n",
      "(-8, 195)\n",
      "Center point (hip) assumed at: (430, 243)\n",
      "Relative keypoints (x, y):\n",
      "(60, -67)\n",
      "(68, -67)\n",
      "(60, -75)\n",
      "(83, -60)\n",
      "(53, -67)\n",
      "(83, -30)\n",
      "(30, -37)\n",
      "(75, 15)\n",
      "(0, 0)\n",
      "(53, 23)\n",
      "(-30, 15)\n",
      "(60, 53)\n",
      "(23, 45)\n",
      "(68, 113)\n",
      "(-15, 113)\n",
      "(60, 165)\n",
      "(-22, 173)\n",
      "Center point (hip) assumed at: (378, 251)\n",
      "Relative keypoints (x, y):\n",
      "(52, -60)\n",
      "(60, -68)\n",
      "(45, -75)\n",
      "(60, -68)\n",
      "(37, -75)\n",
      "(75, -38)\n",
      "(22, -30)\n",
      "(82, 7)\n",
      "(0, 0)\n",
      "(82, 45)\n",
      "(-30, 15)\n",
      "(82, 52)\n",
      "(45, 60)\n",
      "(105, 112)\n",
      "(15, 120)\n",
      "(135, 165)\n",
      "(15, 172)\n",
      "Center point (hip) assumed at: (378, 251)\n",
      "Relative keypoints (x, y):\n",
      "(45, -83)\n",
      "(45, -90)\n",
      "(37, -90)\n",
      "(52, -98)\n",
      "(30, -90)\n",
      "(67, -60)\n",
      "(15, -45)\n",
      "(75, 0)\n",
      "(0, 0)\n",
      "(-378, -251)\n",
      "(-23, 22)\n",
      "(75, 37)\n",
      "(30, 45)\n",
      "(97, 105)\n",
      "(15, 105)\n",
      "(135, 165)\n",
      "(15, 157)\n",
      "Center point (hip) assumed at: (438, 228)\n",
      "Relative keypoints (x, y):\n",
      "(45, -67)\n",
      "(52, -75)\n",
      "(37, -75)\n",
      "(60, -75)\n",
      "(30, -75)\n",
      "(67, -45)\n",
      "(15, -45)\n",
      "(67, 0)\n",
      "(0, 0)\n",
      "(67, 45)\n",
      "(-38, 23)\n",
      "(52, 45)\n",
      "(15, 45)\n",
      "(52, 105)\n",
      "(-15, 113)\n",
      "(52, 173)\n",
      "(-38, 180)\n",
      "Center point (hip) assumed at: (415, 228)\n",
      "Relative keypoints (x, y):\n",
      "(38, -75)\n",
      "(45, -82)\n",
      "(30, -82)\n",
      "(45, -82)\n",
      "(23, -82)\n",
      "(60, -52)\n",
      "(15, -52)\n",
      "(68, -7)\n",
      "(0, 0)\n",
      "(75, 30)\n",
      "(-37, 30)\n",
      "(53, 38)\n",
      "(15, 38)\n",
      "(60, 105)\n",
      "(-7, 113)\n",
      "(60, 173)\n",
      "(-30, 173)\n",
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "# Main processing function to run pose estimation.\n",
    "def run_pose_estimation(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    pafs_output_key = compiled_model.output(\"Mconv7_stage2_L1\")\n",
    "    heatmaps_output_key = compiled_model.output(\"Mconv7_stage2_L2\")\n",
    "    player = None\n",
    "    try:\n",
    "        player = utils.VideoPlayer(source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(title, cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        last_print_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "\n",
    "            black_background = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "            scale = 1280 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            input_img = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "            input_img = input_img.transpose((2, 0, 1))[np.newaxis, ...]\n",
    "\n",
    "            start_time = time.time()\n",
    "            results = compiled_model([input_img])\n",
    "            stop_time = time.time()\n",
    "\n",
    "            pafs = results[pafs_output_key]\n",
    "            heatmaps = results[heatmaps_output_key]\n",
    "            poses, scores = process_results(frame, pafs, heatmaps)\n",
    "\n",
    "            black_background = draw_poses(black_background, poses, 0.1)\n",
    "            \n",
    "            processing_times.append(stop_time - start_time)\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            cv2.putText(black_background, f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\", (20, 40),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if current_time - last_print_time >= 1:\n",
    "                if poses.size > 0:\n",
    "                    for pose in poses:\n",
    "                        keypoints = pose[:, :2].astype(int)\n",
    "                        # 중심점을 허리 좌표 (hip)로 설정 (이 예제에서는 8번 키포인트가 중심점이라고 가정)\n",
    "                        center_x, center_y = keypoints[8]\n",
    "                        print(f\"Center point (hip) assumed at: ({center_x}, {center_y})\")\n",
    "                        print(\"Relative keypoints (x, y):\")\n",
    "                        for keypoint in keypoints:\n",
    "                            relative_x = keypoint[0] - center_x\n",
    "                            relative_y = keypoint[1] - center_y\n",
    "                            print(f\"({relative_x}, {relative_y})\")\n",
    "                else:\n",
    "                    print(\"No poses detected.\")\n",
    "                last_print_time = current_time\n",
    "\n",
    "            if use_popup:\n",
    "                cv2.imshow(title, black_background)\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27:\n",
    "                    break\n",
    "            else:\n",
    "                _, encoded_img = cv2.imencode(\".jpg\", black_background, params=[cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "                img_display = Image(data=encoded_img)\n",
    "                clear_output(wait=True)\n",
    "                display(img_display)\n",
    "            \n",
    "                cv2.imwrite(\"../static/ai.png\", black_background)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run Live Pose Estimation\n",
    "USE_WEBCAM = False\n",
    "cam_id = 0\n",
    "video_file = \"./y2mate.com - Just Dance 2017 PC Unlimited Rasputin 4K_480p.mp4\"\n",
    "source = cam_id if USE_WEBCAM else video_file\n",
    "\n",
    "additional_options = {\"skip_first_frames\": 500} if not USE_WEBCAM else {}\n",
    "run_pose_estimation(source=source, flip=isinstance(source, int), use_popup=True, **additional_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
